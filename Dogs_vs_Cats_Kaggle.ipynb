{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.constraints import maxnorm\n",
    "from keras.regularizers import l2\n",
    "from random import shuffle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_path = \"/home/aiml_test_user/Shaheen/trainDC\"\n",
    "\n",
    "ROWS = 128\n",
    "COLS = 128\n",
    "CHANNELS = 3\n",
    "\n",
    "images = [img for img in os.listdir(train_path)]\n",
    "images_dog = [img for img in os.listdir(train_path) if \"dog\" in img]\n",
    "images_cat = [img for img in os.listdir(train_path) if \"cat\" in img]\n",
    "\n",
    "\n",
    "train_list = images_dog + images_cat\n",
    "\n",
    "shuffle(train_list)\n",
    "\n",
    "train = np.ndarray(shape=(len(train_list),ROWS, COLS))\n",
    "labels = np.ndarray(len(train_list))\n",
    "\n",
    "for i, img_path in enumerate(train_list):\n",
    "    img = cv2.imread(os.path.join(train_path, img_path), 0)\n",
    "    img = cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    train[i] = img\n",
    "    if \"dog\" in img_path:\n",
    "        labels[i] = 1\n",
    "    else:\n",
    "        labels[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train1 = np.array(train).reshape((-1, 1, 128, 128)).astype('float32')\n",
    "\n",
    "train1.shape\n",
    "\n",
    "## dividing by 255\n",
    "train1 /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## splitting the data into train and test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train1, labels, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "\n",
    "## CNN\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=(1, img_size, img_size), activation='relu'))\n",
    "    model.add(Convolution2D(32, 3, 3, activation='relu',border_mode='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model1 = cnn_model()\n",
    "\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17500 samples, validate on 7500 samples\n",
      "Epoch 1/20\n",
      "17500/17500 [==============================] - 56s - loss: 0.6859 - acc: 0.5715 - val_loss: 0.6333 - val_acc: 0.6367\n",
      "Epoch 2/20\n",
      "17500/17500 [==============================] - 60s - loss: 0.6018 - acc: 0.6749 - val_loss: 0.5542 - val_acc: 0.7257\n",
      "Epoch 3/20\n",
      "17500/17500 [==============================] - 60s - loss: 0.5307 - acc: 0.7383 - val_loss: 0.4769 - val_acc: 0.7688\n",
      "Epoch 4/20\n",
      "17500/17500 [==============================] - 60s - loss: 0.4524 - acc: 0.7929 - val_loss: 0.4363 - val_acc: 0.7972\n",
      "Epoch 5/20\n",
      "17500/17500 [==============================] - 60s - loss: 0.3970 - acc: 0.8267 - val_loss: 0.3494 - val_acc: 0.8477\n",
      "Epoch 6/20\n",
      "17500/17500 [==============================] - 60s - loss: 0.3638 - acc: 0.8429 - val_loss: 0.3431 - val_acc: 0.8461\n",
      "Epoch 7/20\n",
      "17500/17500 [==============================] - 60s - loss: 0.3288 - acc: 0.8607 - val_loss: 0.3008 - val_acc: 0.8723\n",
      "Epoch 8/20\n",
      "17500/17500 [==============================] - 60s - loss: 0.3093 - acc: 0.8706 - val_loss: 0.2937 - val_acc: 0.8721\n",
      "Epoch 9/20\n",
      "17500/17500 [==============================] - 60s - loss: 0.2875 - acc: 0.8791 - val_loss: 0.2661 - val_acc: 0.8848\n",
      "Epoch 10/20\n",
      "17500/17500 [==============================] - 60s - loss: 0.2783 - acc: 0.8868 - val_loss: 0.2850 - val_acc: 0.8848\n",
      "Epoch 11/20\n",
      "17500/17500 [==============================] - 59s - loss: 0.2661 - acc: 0.8914 - val_loss: 0.4737 - val_acc: 0.8509\n",
      "Epoch 12/20\n",
      "17500/17500 [==============================] - 59s - loss: 0.2618 - acc: 0.8994 - val_loss: 0.3066 - val_acc: 0.8903\n",
      "Epoch 13/20\n",
      "17500/17500 [==============================] - 59s - loss: 0.2504 - acc: 0.8997 - val_loss: 0.3994 - val_acc: 0.8507\n",
      "Epoch 14/20\n",
      "17500/17500 [==============================] - 59s - loss: 0.2526 - acc: 0.9012 - val_loss: 0.2976 - val_acc: 0.8832\n",
      "Epoch 15/20\n",
      "17500/17500 [==============================] - 59s - loss: 0.2606 - acc: 0.9005 - val_loss: 0.2719 - val_acc: 0.8851\n",
      "Epoch 16/20\n",
      "17500/17500 [==============================] - 59s - loss: 0.2606 - acc: 0.9014 - val_loss: 0.5827 - val_acc: 0.8597\n",
      "Epoch 17/20\n",
      "17500/17500 [==============================] - 59s - loss: 0.2651 - acc: 0.9032 - val_loss: 0.3033 - val_acc: 0.8849\n",
      "Epoch 18/20\n",
      "17500/17500 [==============================] - 59s - loss: 0.2612 - acc: 0.9002 - val_loss: 0.4093 - val_acc: 0.8867\n",
      "Epoch 19/20\n",
      "17500/17500 [==============================] - 59s - loss: 0.2664 - acc: 0.9005 - val_loss: 0.2478 - val_acc: 0.8989\n",
      "Epoch 20/20\n",
      "17500/17500 [==============================] - 59s - loss: 0.2847 - acc: 0.8965 - val_loss: 0.3738 - val_acc: 0.8903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5327ca128>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fitting the model\n",
    "batch_size = 32\n",
    "nb_epoch = 20\n",
    "\n",
    "model1.fit(x_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7488/7500 [============================>.] - ETA: 0sTest accuracy: 0.890266666667\n"
     ]
    }
   ],
   "source": [
    "validation = model1.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test accuracy:', validation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "\n",
    "def catdog():\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=(1, ROWS, COLS), activation='relu'))\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n",
    "    model.add(Convolution2D(256, 3, 3, border_mode='same', activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    return model\n",
    "\n",
    "\n",
    "model3 = catdog()\n",
    "\n",
    "\n",
    "model3.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17500 samples, validate on 7500 samples\n",
      "Epoch 1/14\n",
      "17500/17500 [==============================] - 68s - loss: 0.7112 - acc: 0.5230 - val_loss: 0.6821 - val_acc: 0.5665\n",
      "Epoch 2/14\n",
      "17500/17500 [==============================] - 71s - loss: 0.6714 - acc: 0.6006 - val_loss: 0.6412 - val_acc: 0.6297\n",
      "Epoch 3/14\n",
      "17500/17500 [==============================] - 72s - loss: 0.5885 - acc: 0.6991 - val_loss: 0.7378 - val_acc: 0.6780\n",
      "Epoch 4/14\n",
      "17500/17500 [==============================] - 72s - loss: 0.5102 - acc: 0.7561 - val_loss: 0.4360 - val_acc: 0.8001\n",
      "Epoch 5/14\n",
      "17500/17500 [==============================] - 72s - loss: 0.4598 - acc: 0.7907 - val_loss: 0.3981 - val_acc: 0.8225\n",
      "Epoch 6/14\n",
      "17500/17500 [==============================] - 72s - loss: 0.4071 - acc: 0.8191 - val_loss: 0.3461 - val_acc: 0.8439\n",
      "Epoch 7/14\n",
      "17500/17500 [==============================] - 72s - loss: 0.3687 - acc: 0.8441 - val_loss: 0.3041 - val_acc: 0.8637\n",
      "Epoch 8/14\n",
      "17500/17500 [==============================] - 72s - loss: 0.3295 - acc: 0.8611 - val_loss: 0.2661 - val_acc: 0.8835\n",
      "Epoch 9/14\n",
      "17500/17500 [==============================] - 72s - loss: 0.3129 - acc: 0.8678 - val_loss: 0.3358 - val_acc: 0.8535\n",
      "Epoch 10/14\n",
      "17500/17500 [==============================] - 72s - loss: 0.3041 - acc: 0.8809 - val_loss: 0.3494 - val_acc: 0.8805\n",
      "Epoch 11/14\n",
      "17500/17500 [==============================] - 72s - loss: 0.2942 - acc: 0.8842 - val_loss: 0.2715 - val_acc: 0.8875\n",
      "Epoch 12/14\n",
      "17500/17500 [==============================] - 72s - loss: 0.2818 - acc: 0.8868 - val_loss: 0.2669 - val_acc: 0.8905\n",
      "Epoch 13/14\n",
      "17500/17500 [==============================] - 72s - loss: 0.2962 - acc: 0.8866 - val_loss: 0.3219 - val_acc: 0.8529\n",
      "Epoch 14/14\n",
      "17500/17500 [==============================] - 71s - loss: 0.3080 - acc: 0.8825 - val_loss: 0.2267 - val_acc: 0.9021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa537392128>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fitting the model\n",
    "batch_size = 32\n",
    "nb_epoch = 14\n",
    "\n",
    "model3.fit(x_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7500/7500 [==============================] - 5s     \n",
      "Test accuracy: 0.902133333365\n"
     ]
    }
   ],
   "source": [
    "validation = model3.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test accuracy:', validation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## data augmentation\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(train1, labels, test_size=0.2)\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False, \n",
    "                            featurewise_std_normalization=False, \n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.2,\n",
    "                            shear_range=0.1,\n",
    "                            rotation_range=10.,)\n",
    "\n",
    "datagen1 = ImageDataGenerator(rotation_range=40,\n",
    "                              width_shift_range=0.2,\n",
    "                              height_shift_range=0.2,\n",
    "                              shear_range=0.2,\n",
    "                              zoom_range=0.2,\n",
    "                              horizontal_flip=True)\n",
    "\n",
    "\n",
    "datagen1.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "20000/20000 [==============================] - 64s - loss: 0.7020 - acc: 0.5367 - val_loss: 0.6848 - val_acc: 0.5396\n",
      "Epoch 2/15\n",
      "20000/20000 [==============================] - 67s - loss: 0.6532 - acc: 0.6191 - val_loss: 0.6150 - val_acc: 0.6528\n",
      "Epoch 3/15\n",
      "20000/20000 [==============================] - 67s - loss: 0.6075 - acc: 0.6736 - val_loss: 0.5276 - val_acc: 0.7264\n",
      "Epoch 4/15\n",
      "20000/20000 [==============================] - 66s - loss: 0.5822 - acc: 0.6963 - val_loss: 0.5913 - val_acc: 0.6902\n",
      "Epoch 5/15\n",
      "20000/20000 [==============================] - 66s - loss: 0.5557 - acc: 0.7192 - val_loss: 0.4977 - val_acc: 0.7552\n",
      "Epoch 6/15\n",
      "20000/20000 [==============================] - 66s - loss: 0.5442 - acc: 0.7305 - val_loss: 0.4746 - val_acc: 0.7644\n",
      "Epoch 7/15\n",
      "20000/20000 [==============================] - 66s - loss: 0.5296 - acc: 0.7441 - val_loss: 0.4872 - val_acc: 0.7610\n",
      "Epoch 8/15\n",
      "20000/20000 [==============================] - 66s - loss: 0.5150 - acc: 0.7533 - val_loss: 0.4208 - val_acc: 0.7992\n",
      "Epoch 9/15\n",
      "20000/20000 [==============================] - 66s - loss: 0.5030 - acc: 0.7619 - val_loss: 0.3743 - val_acc: 0.8298\n",
      "Epoch 10/15\n",
      "20000/20000 [==============================] - 66s - loss: 0.4907 - acc: 0.7700 - val_loss: 0.3879 - val_acc: 0.8276\n",
      "Epoch 11/15\n",
      "20000/20000 [==============================] - 66s - loss: 0.4850 - acc: 0.7772 - val_loss: 0.3724 - val_acc: 0.8276\n",
      "Epoch 12/15\n",
      "20000/20000 [==============================] - 66s - loss: 0.4779 - acc: 0.7791 - val_loss: 0.3451 - val_acc: 0.8524\n",
      "Epoch 13/15\n",
      "20000/20000 [==============================] - 66s - loss: 0.4773 - acc: 0.7852 - val_loss: 0.3640 - val_acc: 0.8302\n",
      "Epoch 14/15\n",
      "20000/20000 [==============================] - 65s - loss: 0.4671 - acc: 0.7859 - val_loss: 0.4013 - val_acc: 0.8264\n",
      "Epoch 15/15\n",
      "20000/20000 [==============================] - 65s - loss: 0.4745 - acc: 0.7883 - val_loss: 0.3210 - val_acc: 0.8588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5199b0f28>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reinitialise the model\n",
    "\n",
    "model2 = cnn_model()\n",
    "\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "nb_epoch = 15\n",
    "batch_size = 32\n",
    "model2.fit_generator(datagen1.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                            samples_per_epoch=X_train.shape[0],\n",
    "                            nb_epoch=nb_epoch,\n",
    "                            validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7488/7500 [============================>.] - ETA: 0sTest accuracy: 0.860933333365\n"
     ]
    }
   ],
   "source": [
    "validation = model2.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test accuracy:', validation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## uploading and processing test data\n",
    "test_path = \"/home/aiml_test_user/Shaheen/testDC\"\n",
    "\n",
    "ROWS = 128\n",
    "COLS = 128\n",
    "CHANNELS = 3\n",
    "\n",
    "images = [img for img in os.listdir(test_path)]\n",
    "\n",
    "files = [ os.path.join('/home/aiml_test_user/Shaheen/testDC',str(i)+'.jpg') for i in range(1,12501) ]\n",
    "\n",
    "\n",
    "test = np.ndarray(shape=(len(files),ROWS, COLS))\n",
    "\n",
    "for i, img_path in enumerate(images):\n",
    "    img = cv2.imread(os.path.join(test_path, img_path), 0)\n",
    "    img = cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    test[i] = img\n",
    "    \n",
    "    \n",
    "#for fname in files:\n",
    "    #img = cv2.imread(os.path.join(test_path, img_path), 0)\n",
    "    #img = cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    #test[i] = img\n",
    "                     \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 1, 128, 128)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = np.array(test).reshape((-1, 1, 128, 128)).astype('float32')\n",
    "\n",
    "\n",
    "## dividing by 255\n",
    "test1 /= 255\n",
    "\n",
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## predicting the test data\n",
    "y_pred = model3.predict(test1)\n",
    "\n",
    "# save results\n",
    "np.savetxt('submission_DogsvCatsKaggleProb.csv', np.c_[range(1,len(test1)+1),y_pred], delimiter=',', header = 'id,label', comments = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
