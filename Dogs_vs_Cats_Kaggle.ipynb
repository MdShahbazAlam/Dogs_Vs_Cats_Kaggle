{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5005)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.constraints import maxnorm\n",
    "from keras.regularizers import l2\n",
    "from random import shuffle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import glob\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_path = \"/home/aiml_test_user/Shaheen/trainDC\"\n",
    "\n",
    "ROWS = 128\n",
    "COLS = 128\n",
    "CHANNELS = 3\n",
    "\n",
    "images = [img for img in os.listdir(train_path)]\n",
    "images_dog = [img for img in os.listdir(train_path) if \"dog\" in img]\n",
    "images_cat = [img for img in os.listdir(train_path) if \"cat\" in img]\n",
    "\n",
    "\n",
    "train_list = images_dog + images_cat\n",
    "\n",
    "shuffle(train_list)\n",
    "\n",
    "train = np.ndarray(shape=(len(train_list),ROWS, COLS))\n",
    "labels = np.ndarray(len(train_list))\n",
    "\n",
    "for i, img_path in enumerate(train_list):\n",
    "    img = cv2.imread(os.path.join(train_path, img_path), 0)\n",
    "    img = cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    train[i] = img\n",
    "    if \"dog\" in img_path:\n",
    "        labels[i] = 1\n",
    "    else:\n",
    "        labels[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 128, 128)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 1, 128, 128)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1 = np.array(train).reshape((-1, 1, 128, 128)).astype('float32')\n",
    "\n",
    "train1.shape\n",
    "\n",
    "## dividing by 255\n",
    "train1 /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "## splitting the data into train and test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(train1, labels, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "\n",
    "## CNN\n",
    "\n",
    "def cnn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=(1, img_size, img_size), activation='relu'))\n",
    "    model.add(Convolution2D(32, 3, 3, activation='relu',border_mode='same'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same', activation='relu'))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Convolution2D(128, 3, 3, border_mode='same', activation='relu'))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model1 = cnn_model()\n",
    "\n",
    "\n",
    "model1.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17500 samples, validate on 7500 samples\n",
      "Epoch 1/2\n",
      "17500/17500 [==============================] - 56s - loss: 0.3080 - acc: 0.8894 - val_loss: 0.4444 - val_acc: 0.9012\n",
      "Epoch 2/2\n",
      "17500/17500 [==============================] - 59s - loss: 0.3063 - acc: 0.8955 - val_loss: 0.2508 - val_acc: 0.8899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4014888198>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fitting the model\n",
    "batch_size = 32\n",
    "nb_epoch = 24\n",
    "\n",
    "model1.fit(x_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "          verbose=1, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7488/7500 [============================>.] - ETA: 0sTest accuracy: 0.888399999968\n"
     ]
    }
   ],
   "source": [
    "validation = model1.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test accuracy:', validation[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## data augmentation\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(train1, labels, test_size=0.2)\n",
    "\n",
    "\n",
    "datagen = ImageDataGenerator(featurewise_center=False, \n",
    "                            featurewise_std_normalization=False, \n",
    "                            width_shift_range=0.1,\n",
    "                            height_shift_range=0.1,\n",
    "                            zoom_range=0.2,\n",
    "                            shear_range=0.1,\n",
    "                            rotation_range=10.,)\n",
    "\n",
    "datagen1 = ImageDataGenerator(rotation_range=40,\n",
    "                              width_shift_range=0.2,\n",
    "                              height_shift_range=0.2,\n",
    "                              shear_range=0.2,\n",
    "                              zoom_range=0.2,\n",
    "                              horizontal_flip=True)\n",
    "\n",
    "\n",
    "datagen1.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20000/20000 [==============================] - 65s - loss: 0.7069 - acc: 0.5419 - val_loss: 0.6792 - val_acc: 0.5540\n",
      "Epoch 2/5\n",
      "20000/20000 [==============================] - 67s - loss: 0.6516 - acc: 0.6260 - val_loss: 0.6285 - val_acc: 0.6582\n",
      "Epoch 3/5\n",
      "20000/20000 [==============================] - 66s - loss: 0.6167 - acc: 0.6665 - val_loss: 0.5324 - val_acc: 0.7224\n",
      "Epoch 4/5\n",
      "20000/20000 [==============================] - 66s - loss: 0.5945 - acc: 0.6865 - val_loss: 0.4882 - val_acc: 0.7674\n",
      "Epoch 5/5\n",
      "20000/20000 [==============================] - 65s - loss: 0.5757 - acc: 0.7013 - val_loss: 0.4892 - val_acc: 0.7608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fee6e9777f0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reinitialise the model\n",
    "\n",
    "model2 = cnn_model()\n",
    "\n",
    "\n",
    "model2.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "nb_epoch = 5\n",
    "batch_size = 32\n",
    "model2.fit_generator(datagen1.flow(X_train, Y_train, batch_size=batch_size),\n",
    "                            samples_per_epoch=X_train.shape[0],\n",
    "                            nb_epoch=nb_epoch,\n",
    "                            validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## uploading and processing test data\n",
    "test_path = \"/home/aiml_test_user/Shaheen/testDC\"\n",
    "\n",
    "ROWS = 128\n",
    "COLS = 128\n",
    "CHANNELS = 3\n",
    "\n",
    "images = [img for img in os.listdir(test_path)]\n",
    "\n",
    "files = [ os.path.join('/home/aiml_test_user/Shaheen/testDC',str(i)+'.jpg') for i in range(1,12501) ]\n",
    "\n",
    "\n",
    "test = np.ndarray(shape=(len(files),ROWS, COLS))\n",
    "\n",
    "for i, img_path in enumerate(images):\n",
    "    img = cv2.imread(os.path.join(test_path, img_path), 0)\n",
    "    img = cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    test[i] = img\n",
    "    \n",
    "    \n",
    "#for fname in files:\n",
    "    #img = cv2.imread(os.path.join(test_path, img_path), 0)\n",
    "    #img = cv2.resize(img, (ROWS, COLS), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    #test[i] = img\n",
    "                     \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 1, 128, 128)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = np.array(test).reshape((-1, 1, 128, 128)).astype('float32')\n",
    "\n",
    "\n",
    "## dividing by 255\n",
    "test1 /= 255\n",
    "\n",
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## predicting the test data\n",
    "y_pred = model1.predict(test1)\n",
    "\n",
    "# save results\n",
    "np.savetxt('submission_DogsvCatsKaggleProb.csv', np.c_[range(1,len(test1)+1),y_pred], delimiter=',', header = 'id,label', comments = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12660949], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save results\n",
    "np.savetxt('submission_DogsvCatsKaggleProb.csv', np.c_[range(1,len(test1)+1),y_pred], delimiter=',', header = 'id,label', comments = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
